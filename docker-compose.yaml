version: '3'

services:
  llama:
    image: ghcr.io/abetlen/llama-cpp-python:latest
    container_name: llama-cpp
    ports:
      - "8000:8000"
    volumes:
      - ./models:/models
    environment:
      - MODEL=/models/llama-2-7b-chat.Q4_K_M.gguf
      - THREADS=4
      - N_CTX=4096
    restart: unless-stopped

  clyde-bot:
    build: ./bot
    container_name: clyde-bot
    depends_on:
      - llama
    environment:
      - PYTHONUNBUFFERED=1
    restart: unless-stopped